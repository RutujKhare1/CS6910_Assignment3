{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport numpy as np\nimport pandas as pd\nimport torch\nimport random\nimport wandb\nimport torch.nn as nn","metadata":{"id":"U2XJa6S3Yk4B","execution":{"iopub.status.busy":"2023-05-09T16:45:49.965412Z","iopub.execute_input":"2023-05-09T16:45:49.966406Z","iopub.status.idle":"2023-05-09T16:45:51.873741Z","shell.execute_reply.started":"2023-05-09T16:45:49.966353Z","shell.execute_reply":"2023-05-09T16:45:51.872832Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device_name = torch.device(\"cuda\")\nelse:\n    device_name = torch.device('cpu')\nprint(\"Using {}.\".format(device_name))","metadata":{"id":"bZG0Efld9B2w","outputId":"66a2b409-d1dc-4fdf-fd62-5692a5c66f9b","execution":{"iopub.status.busy":"2023-05-09T16:45:51.876636Z","iopub.execute_input":"2023-05-09T16:45:51.877256Z","iopub.status.idle":"2023-05-09T16:45:51.941299Z","shell.execute_reply.started":"2023-05-09T16:45:51.877219Z","shell.execute_reply":"2023-05-09T16:45:51.940158Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using cuda.\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocessingData(df):\n    eng_maxlen = len(max(df['eng'], key=len))\n    hin_maxlen = len(max(df['hin'], key=len))\n    max_len = max(eng_maxlen, hin_maxlen)\n    eng_words = df['eng'].copy()\n    for i in range(len(eng_words)):\n        l = len(eng_words[i])\n        eng_words[i] = eng_words[i] + \"*\"*(max_len - l + 3)\n    hin_words = df['hin'].copy()\n    for i in range(len(hin_words)):\n        l = len(hin_words[i])\n        hin_words[i] = \"#\" + hin_words[i] + \"*\"*(max_len - l + 2)\n    unique_eng_letters = set(''.join(eng_words))\n    unique_hin_letters = set(''.join(hin_words))\n    int_to_eng = dict(enumerate(unique_eng_letters))\n    eng_to_int = {char: ind for ind, char in int_to_eng.items()}\n\n    int_to_hin = dict(enumerate(unique_hin_letters))\n    hin_to_int = {char: ind for ind, char in int_to_hin.items()}\n\n    index_eng_words = []\n    for eng_word in eng_words:\n        index_eng_word = [eng_to_int[i] for i in eng_word]\n        index_eng_words.append(index_eng_word)\n    index_hin_words = []\n    for hin_word in hin_words:\n        index_hin_word = [hin_to_int[i] for i in hin_word]\n        index_hin_words.append(index_hin_word)\n    tensor_eng = torch.tensor(index_eng_words).to(device_name)\n    tensor_hin = torch.tensor(index_hin_words).to(device_name)\n    return tensor_eng, tensor_hin, int_to_eng, int_to_hin, unique_eng_letters, unique_hin_letters\n","metadata":{"execution":{"iopub.status.busy":"2023-05-09T16:45:51.969526Z","iopub.execute_input":"2023-05-09T16:45:51.971188Z","iopub.status.idle":"2023-05-09T16:45:51.980747Z","shell.execute_reply.started":"2023-05-09T16:45:51.971157Z","shell.execute_reply":"2023-05-09T16:45:51.979691Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class GRU_Encoder(nn.Module):\n    def __init__(self, input_size, hid_size, num_of_enc_layers, emb_size, batch_size, dropout, bi_direct):\n        super(GRU_Encoder, self).__init__()\n        self.input_size = input_size\n        self.hid_size = hid_size\n        self.num_of_enc_layers = num_of_enc_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.dropout = dropout\n        self.embedding = nn.Embedding(input_size, emb_size)\n        # print(\"IS:{} ES:{}\".format(input_size, emb_size))\n        self.gru = nn.GRU(emb_size, hid_size, num_of_enc_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden):\n        input_data = input_data.T\n        # print(input_data.shape)\n        embed = self.embedding(input_data).to(device_name)\n        # print(embed.shape,hidden.shape)\n        # embed = embed.view(-1, self.batch_size, self.hid_size)\n        output, hidden = self.gru(embed, hidden)\n        # if(self.bi_direct):\n        #   print(\"bir\\n\")\n        #   hidden = hidden.resize(2, self.num_of_enc_layers, self.batch_size, self.hid_size)\n        #   print(hidden.shape)\n        #   hidden = torch.add(hidden[0], hidden[1])/2\n        #   print(hidden.shape)\n        return output, hidden\n\n    def initialiseHidden(self):\n        if(self.bi_direct):\n            return torch.zeros(2*self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n        else:\n            return torch.zeros(self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n","metadata":{"id":"S4q529z-FjCx","execution":{"iopub.status.busy":"2023-05-09T16:45:52.500715Z","iopub.execute_input":"2023-05-09T16:45:52.502353Z","iopub.status.idle":"2023-05-09T16:45:52.511000Z","shell.execute_reply.started":"2023-05-09T16:45:52.502311Z","shell.execute_reply":"2023-05-09T16:45:52.510080Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class GRU_Decoder(nn.Module):\n    def __init__(self, op_size, num_of_dec_layers, hid_size, batch_size, emb_size, dropout, bi_direct):\n        super(GRU_Decoder, self).__init__()\n        self.op_size = op_size\n        self.hid_size = hid_size\n        self.num_of_dec_layers = num_of_dec_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.embedding = nn.Embedding(op_size, emb_size)\n        self.op = nn.Linear(2*hid_size, op_size) if (bi_direct) else nn.Linear(hid_size, op_size)\n        self.softmax = nn.LogSoftmax(dim = 2)\n        self.gru = nn.GRU(emb_size, hid_size, num_of_dec_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden):\n        # print(input_data)\n        embed = self.embedding(input_data)\n        embed = embed.view(-1, self.batch_size, self.emb_size)\n        #     print(hidden.shape)\n        out, hidden = self.gru(embed, hidden)\n        # print(out.shape)\n        temp = self.op(out)\n        out = self.softmax(temp)\n        return out, hidden","metadata":{"id":"uDr5Mjb6Fi0a","execution":{"iopub.status.busy":"2023-05-09T16:45:52.829392Z","iopub.execute_input":"2023-05-09T16:45:52.829667Z","iopub.status.idle":"2023-05-09T16:45:52.839725Z","shell.execute_reply.started":"2023-05-09T16:45:52.829642Z","shell.execute_reply":"2023-05-09T16:45:52.838892Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class RNN_Encoder(nn.Module):\n    def __init__(self, input_size, hid_size, num_of_enc_layers, emb_size, batch_size, dropout, bi_direct):\n        super(RNN_Encoder, self).__init__()\n        self.input_size = input_size\n        self.hid_size = hid_size\n        self.num_of_enc_layers = num_of_enc_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.dropout = dropout\n        self.embedding = nn.Embedding(input_size, emb_size)\n        self.rnn = nn.RNN(emb_size, hid_size, num_of_enc_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden):\n        input_data = input_data.T\n        embed = self.embedding(input_data).to(device_name)\n        output, hidden = self.rnn(embed, hidden)\n        return output, hidden\n\n    def initialiseHidden(self):\n        if(self.bi_direct):\n            return torch.zeros(2*self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n        else:\n            return torch.zeros(self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-09T16:45:53.117344Z","iopub.execute_input":"2023-05-09T16:45:53.117680Z","iopub.status.idle":"2023-05-09T16:45:53.126862Z","shell.execute_reply.started":"2023-05-09T16:45:53.117652Z","shell.execute_reply":"2023-05-09T16:45:53.125779Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class RNN_Decoder(nn.Module):\n    def __init__(self, op_size, num_of_dec_layers, hid_size, batch_size, emb_size, dropout, bi_direct):\n        super(RNN_Decoder, self).__init__()\n        self.op_size = op_size\n        self.hid_size = hid_size\n        self.num_of_dec_layers = num_of_dec_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.embedding = nn.Embedding(op_size, emb_size)\n        self.op = nn.Linear(2*hid_size, op_size) if (bi_direct) else nn.Linear(hid_size, op_size)\n        self.softmax = nn.LogSoftmax(dim = 2)\n        self.rnn = nn.RNN(emb_size, hid_size, num_of_dec_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden):\n        embed = self.embedding(input_data)\n        embed = embed.view(-1, self.batch_size, self.emb_size)\n        out, hidden = self.rnn(embed, hidden)\n        temp = self.op(out)\n        out = self.softmax(temp)\n        return out, hidden","metadata":{"execution":{"iopub.status.busy":"2023-05-09T16:45:53.374838Z","iopub.execute_input":"2023-05-09T16:45:53.375398Z","iopub.status.idle":"2023-05-09T16:45:53.383263Z","shell.execute_reply.started":"2023-05-09T16:45:53.375363Z","shell.execute_reply":"2023-05-09T16:45:53.382112Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class LSTM_Encoder(nn.Module):\n    def __init__(self, input_size, hid_size, num_of_enc_layers, emb_size, batch_size, dropout, bi_direct):\n        super(LSTM_Encoder, self).__init__()\n        self.input_size = input_size\n        self.hid_size = hid_size\n        self.num_of_enc_layers = num_of_enc_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.dropout = dropout\n        self.embedding = nn.Embedding(input_size, emb_size)\n        self.lstm = nn.LSTM(emb_size, hid_size, num_of_enc_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden, state):\n        input_data = input_data.T\n        embed = self.embedding(input_data).to(device_name)\n        output, (hidden, state) = self.lstm(embed, (hidden, state))\n        return output, hidden, state\n\n    def initialiseHidden(self):\n        if(self.bi_direct):\n            return torch.zeros(2*self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n        else:\n            return torch.zeros(self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:14.480489Z","iopub.execute_input":"2023-05-09T17:35:14.481158Z","iopub.status.idle":"2023-05-09T17:35:14.489934Z","shell.execute_reply.started":"2023-05-09T17:35:14.481100Z","shell.execute_reply":"2023-05-09T17:35:14.489078Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class LSTM_Decoder(nn.Module):\n    def __init__(self, op_size, num_of_dec_layers, hid_size, batch_size, emb_size, dropout, bi_direct):\n        super(LSTM_Decoder, self).__init__()\n        self.op_size = op_size\n        self.hid_size = hid_size\n        self.num_of_dec_layers = num_of_dec_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.embedding = nn.Embedding(op_size, emb_size)\n        self.op = nn.Linear(2*hid_size, op_size) if (bi_direct) else nn.Linear(hid_size, op_size)\n        self.softmax = nn.LogSoftmax(dim = 2)\n        self.lstm = nn.LSTM(emb_size, hid_size, num_of_dec_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden, state):\n        embed = self.embedding(input_data)\n        embed = embed.view(-1, self.batch_size, self.emb_size)\n        out, (hidden, state) = self.lstm(embed, (hidden, state))\n        temp = self.op(out)\n        out = self.softmax(temp)\n        return out, hidden, state","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:15.187096Z","iopub.execute_input":"2023-05-09T17:35:15.187954Z","iopub.status.idle":"2023-05-09T17:35:15.195761Z","shell.execute_reply.started":"2023-05-09T17:35:15.187907Z","shell.execute_reply":"2023-05-09T17:35:15.194627Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n    teacher_forcing = 0.5\n    loss = 0\n    for b in range(0, len(input_data), batch_size):\n        x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n        temp = 0\n        enc_optimizer.zero_grad()\n        dec_optimizer.zero_grad()\n        if(cell_type == 'GRU' or cell_type == 'RNN'):\n            enc_hidden = encoder.initialiseHidden()\n            enc_output, enc_hidden = encoder(x, enc_hidden)\n            dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_hidden = dec_hidden.repeat(2,1,1)\n            y = y.T\n            dec_input = y[0]\n            #       print(\"AFT_Decoder Hidden : {}\".format(dec_hidden.shape))\n            condition = False if random.random() > teacher_forcing else True\n            if(condition):\n                for i in range(len(y)):\n                    dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n                    temp += loss_fn(torch.squeeze(dec_output), y[i])\n                    dec_input = y[i]\n            else:\n                for i in range(len(y)):\n                    dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n                    prob, idx = dec_output.topk(1)\n                    temp += loss_fn(torch.squeeze(dec_output), y[i])\n                    dec_input = idx\n                    \n        elif(cell_type == 'LSTM'):\n            enc_hidden = encoder.initialiseHidden()\n            enc_state = encoder.initialiseHidden()\n            \n            enc_output, enc_hidden, enc_state = encoder(x, enc_hidden, enc_state)\n            dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_hidden = dec_hidden.repeat(2,1,1)\n            \n            dec_state = enc_state[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_state = dec_state.repeat(2,1,1)\n            y = y.T\n            dec_input = y[0]\n            #       print(\"AFT_Decoder Hidden : {}\".format(dec_hidden.shape))\n            condition = False if random.random() > teacher_forcing else True\n            if(condition):\n                for i in range(len(y)):\n                    dec_output, dec_hidden, dec_state = decoder(dec_input, dec_hidden, dec_state)\n                    temp += loss_fn(torch.squeeze(dec_output), y[i])\n                    dec_input = y[i]\n            else:\n                for i in range(len(y)):\n                    dec_output, dec_hidden, dec_state = decoder(dec_input, dec_hidden, dec_state)\n                    prob, idx = dec_output.topk(1)\n                    temp += loss_fn(torch.squeeze(dec_output), y[i])\n                    dec_input = idx\n        \n        temp.backward()\n        enc_optimizer.step()\n        dec_optimizer.step()\n        loss += temp\n\n    return loss.item()/(len(target_data) * target_data.shape[1]), encoder, decoder\n\n","metadata":{"id":"KToV_mC2WtPI","execution":{"iopub.status.busy":"2023-05-09T17:35:17.210212Z","iopub.execute_input":"2023-05-09T17:35:17.210954Z","iopub.status.idle":"2023-05-09T17:35:17.225713Z","shell.execute_reply.started":"2023-05-09T17:35:17.210912Z","shell.execute_reply":"2023-05-09T17:35:17.224739Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def eval(input_data, target_data, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n    out = []\n    for b in range(0, len(input_data), batch_size):\n        x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n        encoder.eval()\n        decoder.eval()\n        predicted_data = list()\n        if(cell_type == 'GRU' or cell_type == 'RNN'):\n            enc_hidden = encoder.initialiseHidden()\n            enc_output, enc_hidden = encoder(x, enc_hidden)\n            y = y.T      \n            dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n            #dec_hidden = enc_hidden\n            dec_input = y[0]\n            if bi_direct:\n                dec_hidden = dec_hidden.repeat(2,1,1)\n            for i in range(len(y)):\n                dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n                prob, idx = dec_output.topk(1)\n                idx = idx.squeeze()\n                dec_input = idx\n                predicted_data.append(idx.tolist())\n            out.append(predicted_data)\n        elif(cell_type == 'LSTM'):\n            enc_hidden = encoder.initialiseHidden()\n            enc_state = encoder.initialiseHidden()\n            enc_output, enc_hidden, enc_state = encoder(x, enc_hidden, enc_state)\n            y = y.T      \n            dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_hidden = dec_hidden.repeat(2,1,1)\n                \n            dec_state = enc_state[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_state = dec_state.repeat(2,1,1)\n            \n            dec_input = y[0]\n            for i in range(len(y)):\n                dec_output, dec_hidden, dec_state = decoder(dec_input, dec_hidden, dec_state)\n                prob, idx = dec_output.topk(1)\n                idx = idx.squeeze()\n                dec_input = idx\n                predicted_data.append(idx.tolist())\n            out.append(predicted_data)\n    return out","metadata":{"id":"tosOCKpmU49G","execution":{"iopub.status.busy":"2023-05-09T17:35:17.962339Z","iopub.execute_input":"2023-05-09T17:35:17.963005Z","iopub.status.idle":"2023-05-09T17:35:17.973087Z","shell.execute_reply.started":"2023-05-09T17:35:17.962963Z","shell.execute_reply":"2023-05-09T17:35:17.972196Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# def eval(input_data, target_data, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n#     out = []\n#   for b in range(0, len(input_data), batch_size):\n#     x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n#     encoder.eval()\n#     decoder.eval()\n#     predicted_data = list()\n#     if(cell_type == 'GRU'):\n#       enc_hidden = encoder.initialiseHidden()\n#       enc_output, enc_hidden = encoder(x, enc_hidden)\n#       y = y.T      \n#       dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n#       #dec_hidden = enc_hidden\n#       dec_input = y[0]\n#       if bi_direct:\n#             dec_hidden = dec_hidden.repeat(2,1,1)\n#       for i in range(len(y)):\n#         dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n#         prob, idx = dec_output.topk(1)\n#         idx = idx.squeeze()\n#         dec_input = idx\n#         predicted_data.append(idx.tolist())\n#       out.append(predicted_data)\n#   return out","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:18.920086Z","iopub.execute_input":"2023-05-09T17:35:18.921093Z","iopub.status.idle":"2023-05-09T17:35:18.926508Z","shell.execute_reply.started":"2023-05-09T17:35:18.921054Z","shell.execute_reply":"2023-05-09T17:35:18.925568Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# def training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size):\n#   learning_rate = 0.001\n#   if(cell_type == \"GRU\"):\n#     encoder = GRU_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n#     decoder = GRU_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n#   elif(cell_typ == \"RNN\"):\n#     encoder = RNN_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n#     decoder = RNN_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n  \n#   enc_optimizer = torch.optim.Adam(encoder.parameters(), learning_rate)\n#   dec_optimizer = torch.optim.Adam(decoder.parameters(), learning_rate)\n#   loss_fn = nn.CrossEntropyLoss(reduction = 'sum')\n#   encoder.train()\n#   decoder.train()\n#   loss_list = []\n#   for i in range(epochs):\n#     loss, encoder, decoder = train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\n#     loss_list.append(loss/51200)\n#     print(\"Epoch : {} \\tLoss : {}\".format(i, loss))\n\n#   return encoder, decoder, num_of_enc_layers, num_of_dec_layers\n","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:19.280199Z","iopub.execute_input":"2023-05-09T17:35:19.281239Z","iopub.status.idle":"2023-05-09T17:35:19.286688Z","shell.execute_reply.started":"2023-05-09T17:35:19.281196Z","shell.execute_reply":"2023-05-09T17:35:19.285486Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# def train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n#     teacher_forcing = 0.5\n#     loss = 0\n#     for b in range(0, len(input_data), batch_size):\n#         x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n#         temp = 0\n#         enc_optimizer.zero_grad()\n#         dec_optimizer.zero_grad()\n#         if(cell_type == 'GRU' or cell_type == 'RNN'):\n#             enc_hidden = encoder.initialiseHidden()\n#             enc_output, enc_hidden = encoder(x, enc_hidden)\n#             #       print(\"AFT_Encoder Hidden : {}\".format(enc_hidden.shape))\n#             #       if(num_of_dec_layers > num_of_enc_layers):\n#             # #         print(\"1\")\n#             #         num = num_of_dec_layers-2\n#             #         dec_hidden = enc_hidden\n#             #         while(num != num_of_enc_layers):\n#             #           dec_hidden = torch.cat([dec_hidden, enc_hidden[-1].unsqueeze(0)], dim = 0)\n#             #           num -= 1\n#             #       elif(num_of_dec_layers < num_of_enc_layers):\n#             # #         print(\"2\")\n#             #         dec_hidden = enc_hidden[-num_of_dec_layers:]\n#             #       else:\n#             # #         print(\"3\")\n#             #         dec_hidden = enc_hidden\n#             dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n#             #dec_hidden = enc_hidden\n#             if bi_direct:\n#                 dec_hidden = dec_hidden.repeat(2,1,1)\n#             y = y.T\n#             dec_input = y[0]\n#             #       print(\"AFT_Decoder Hidden : {}\".format(dec_hidden.shape))\n#             condition = False if random.random() > teacher_forcing else True\n#             if(condition):\n#                 for i in range(len(y)):\n#                     dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n#                     temp += loss_fn(torch.squeeze(dec_output), y[i])\n#                     dec_input = y[i]\n#             else:\n#                 for i in range(len(y)):\n#                     dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n#                     prob, idx = dec_output.topk(1)\n#                     temp += loss_fn(torch.squeeze(dec_output), y[i])\n#                     dec_input = idx\n#             temp.backward()\n#             enc_optimizer.step()\n#             dec_optimizer.step()\n#             loss += temp\n\n#     return loss.item()/(len(target_data) * target_data.shape[1]), encoder, decoder\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:19.760555Z","iopub.execute_input":"2023-05-09T17:35:19.760887Z","iopub.status.idle":"2023-05-09T17:35:19.767645Z","shell.execute_reply.started":"2023-05-09T17:35:19.760857Z","shell.execute_reply":"2023-05-09T17:35:19.766578Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size):\n    learning_rate = 0.001\n    if(cell_type == \"GRU\"):\n        encoder = GRU_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n        decoder = GRU_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n    elif(cell_type == \"RNN\"):\n        encoder = RNN_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n        decoder = RNN_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n    elif(cell_type == \"LSTM\"):\n        encoder = LSTM_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n        decoder = LSTM_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n\n    enc_optimizer = torch.optim.Adam(encoder.parameters(), learning_rate)\n    dec_optimizer = torch.optim.Adam(decoder.parameters(), learning_rate)\n    loss_fn = nn.NLLLoss(reduction = 'sum')\n    encoder.train()\n    decoder.train()\n    loss_list = []\n    for i in range(epochs):\n        loss, encoder, decoder = train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\n        loss_list.append(loss/51200)\n        print(\"Epoch : {} \\tLoss : {}\".format(i, loss))\n\n    return encoder, decoder, num_of_enc_layers, num_of_dec_layers\n","metadata":{"id":"ifkAGoezFiwH","execution":{"iopub.status.busy":"2023-05-09T17:35:53.888774Z","iopub.execute_input":"2023-05-09T17:35:53.889105Z","iopub.status.idle":"2023-05-09T17:35:53.897699Z","shell.execute_reply.started":"2023-05-09T17:35:53.889076Z","shell.execute_reply":"2023-05-09T17:35:53.896799Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def calculateAccuracy(y_pred, y_true):\n    cnt = 0\n    for i,j in zip(y_pred, y_true):\n        cor = torch.eq(i, j)\n        if(torch.mean(cor.float()).item() == 1.0):\n            cnt += 1\n    return cnt / len(y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:56.197188Z","iopub.execute_input":"2023-05-09T17:35:56.197547Z","iopub.status.idle":"2023-05-09T17:35:56.203069Z","shell.execute_reply.started":"2023-05-09T17:35:56.197516Z","shell.execute_reply":"2023-05-09T17:35:56.201953Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/fdl-a3/hin_train.csv', names=['eng','hin'])\ntensor_eng, tensor_hin, int_to_eng, int_to_hin, unique_eng_letters, unique_hin_letters = preprocessingData(df)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:57.671069Z","iopub.execute_input":"2023-05-09T17:35:57.671438Z","iopub.status.idle":"2023-05-09T17:35:59.793952Z","shell.execute_reply.started":"2023-05-09T17:35:57.671407Z","shell.execute_reply":"2023-05-09T17:35:59.793015Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"input_data = tensor_eng\ninput_size = len(unique_eng_letters)\ntarget_data = tensor_hin\ntarget_size = len(unique_hin_letters) \nmax_input_size = tensor_eng.shape[1] \nepochs = 7\nbatch_size = 64 \nemb_size = 256 \nnum_of_enc_layers = 1\nnum_of_dec_layers = 3\nhid_size = 256\ncell_type = \"LSTM\" \nbi_direct = True \nenc_dropout = 0.3\ndec_dropout = 0.3 \nbeam_size = 1","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:36:02.780109Z","iopub.execute_input":"2023-05-09T17:36:02.780548Z","iopub.status.idle":"2023-05-09T17:36:02.791368Z","shell.execute_reply.started":"2023-05-09T17:36:02.780511Z","shell.execute_reply":"2023-05-09T17:36:02.790500Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"encoder, decoder, num_of_enc_layers, num_of_dec_layers = training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size)","metadata":{"id":"Us7xCAvmwhbE","outputId":"2a475a4b-106d-4958-f7bc-f1df04d947cf","execution":{"iopub.status.busy":"2023-05-09T17:36:03.402749Z","iopub.execute_input":"2023-05-09T17:36:03.403091Z","iopub.status.idle":"2023-05-09T17:42:14.636786Z","shell.execute_reply.started":"2023-05-09T17:36:03.403062Z","shell.execute_reply":"2023-05-09T17:42:14.635674Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 0 \tLoss : 0.5919310619212963\nEpoch : 1 \tLoss : 0.3397856987847222\nEpoch : 2 \tLoss : 0.289686279296875\nEpoch : 3 \tLoss : 0.2565958884910301\nEpoch : 4 \tLoss : 0.23477620442708333\nEpoch : 5 \tLoss : 0.2176193802445023\nEpoch : 6 \tLoss : 0.20138111255787036\n","output_type":"stream"}]},{"cell_type":"code","source":"trained_pred = eval(tensor_eng, tensor_hin, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)","metadata":{"id":"9kejVozOEl_o","execution":{"iopub.status.busy":"2023-05-09T17:42:19.404877Z","iopub.execute_input":"2023-05-09T17:42:19.405243Z","iopub.status.idle":"2023-05-09T17:42:35.531434Z","shell.execute_reply.started":"2023-05-09T17:42:19.405212Z","shell.execute_reply":"2023-05-09T17:42:35.530489Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"torch.tensor(trained_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:42:35.533496Z","iopub.execute_input":"2023-05-09T17:42:35.533871Z","iopub.status.idle":"2023-05-09T17:42:35.799831Z","shell.execute_reply.started":"2023-05-09T17:42:35.533837Z","shell.execute_reply":"2023-05-09T17:42:35.798767Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 8,  8,  8,  ...,  8,  8,  8],\n         [48, 21, 41,  ..., 49, 57, 41],\n         [62, 24, 24,  ...,  2, 62, 36],\n         ...,\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64]],\n\n        [[ 8,  8,  8,  ...,  8,  8,  8],\n         [45,  1, 11,  ..., 41, 14, 41],\n         [55, 55,  5,  ..., 44, 23,  7],\n         ...,\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64]],\n\n        [[ 8,  8,  8,  ...,  8,  8,  8],\n         [41, 21, 15,  ...,  9, 11, 45],\n         [24, 55, 13,  ...,  5, 19, 55],\n         ...,\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64]],\n\n        ...,\n\n        [[ 8,  8,  8,  ...,  8,  8,  8],\n         [16, 14,  9,  ..., 21, 11, 61],\n         [ 7,  7, 49,  ..., 36, 62, 44],\n         ...,\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64]],\n\n        [[ 8,  8,  8,  ...,  8,  8,  8],\n         [41, 45, 41,  ..., 61,  1, 61],\n         [ 5, 49, 36,  ..., 44, 24,  5],\n         ...,\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64]],\n\n        [[ 8,  8,  8,  ...,  8,  8,  8],\n         [61,  3, 43,  ..., 43,  3, 43],\n         [ 2, 24,  7,  ...,  3,  2,  7],\n         ...,\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64],\n         [64, 64, 64,  ..., 64, 64, 64]]])"},"metadata":{}}]},{"cell_type":"code","source":"out = []\nten_pred = torch.tensor(trained_pred)\nfor i in range(len(trained_pred)):\n    temp = ten_pred[i].T\n    out.extend(temp)\nout_pred = torch.stack(out).to(device_name)\nprint(calculateAccuracy(out_pred, tensor_hin))","metadata":{"id":"LyHQWp5kI_gP","execution":{"iopub.status.busy":"2023-05-09T17:42:45.190958Z","iopub.execute_input":"2023-05-09T17:42:45.191313Z","iopub.status.idle":"2023-05-09T17:42:48.112184Z","shell.execute_reply.started":"2023-05-09T17:42:45.191282Z","shell.execute_reply":"2023-05-09T17:42:48.111178Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"0.47244140625\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/fdl-a3/hin_test.csv', names=['eng','hin'])\n\neng_words = df_test['eng'].copy()\nfor i in range(len(eng_words)):\n    l = len(eng_words[i])\n    eng_words[i] = eng_words[i] + \"*\"*(24 - l + 3)\nhin_words = df_test['hin'].copy()\nfor i in range(len(hin_words)):\n    l = len(hin_words[i])\n    hin_words[i] = \"#\" + hin_words[i] + \"*\"*(24 - l + 2)\n    \neng_to_int = {v: k for k, v in int_to_eng.items()}\nhin_to_int = {v: k for k, v in int_to_hin.items()}\nhin_to_int['_'] = len(hin_to_int)","metadata":{"id":"g7cyXu1OcIx0","outputId":"b6f77907-8198-49c8-eb4e-3946b47637d8","execution":{"iopub.status.busy":"2023-05-09T17:42:52.714662Z","iopub.execute_input":"2023-05-09T17:42:52.715045Z","iopub.status.idle":"2023-05-09T17:42:52.843335Z","shell.execute_reply.started":"2023-05-09T17:42:52.715011Z","shell.execute_reply":"2023-05-09T17:42:52.842502Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"index_eng_words = []\nfor eng_word in eng_words:\n    index_eng_word = [eng_to_int[i] for i in eng_word]\n    index_eng_words.append(index_eng_word)\nindex_hin_words = []\nfor hin_word in hin_words:\n    index_hin_word = [hin_to_int[i] if i in hin_to_int else hin_to_int['_'] for i in hin_word]\n    index_hin_words.append(index_hin_word)\n\ntensor_eng_test = torch.tensor(index_eng_words).to(device_name)\ntensor_hin_test = torch.tensor(index_hin_words).to(device_name)\n\ntrained_pred = eval(tensor_eng_test, tensor_hin_test, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\nout = []\nten_pred = torch.tensor(trained_pred)\nfor i in range(len(trained_pred)):\n    temp = ten_pred[i].T\n    out.extend(temp)\nout_pred = torch.stack(out).to(device_name)\nprint(calculateAccuracy(out_pred, tensor_hin_test))","metadata":{"id":"4kA10NUNLaqR","outputId":"21a4d7a9-0f74-4650-c6d5-8877cdef6f92","execution":{"iopub.status.busy":"2023-05-09T17:42:54.327414Z","iopub.execute_input":"2023-05-09T17:42:54.327791Z","iopub.status.idle":"2023-05-09T17:42:55.985000Z","shell.execute_reply.started":"2023-05-09T17:42:54.327748Z","shell.execute_reply":"2023-05-09T17:42:55.983812Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"0.32763671875\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# SWEEP CONFIG","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Experimental Area**","metadata":{"id":"6h-qHdB__elc"}},{"cell_type":"code","source":"l = [i if i!=5 else 99 for i in range(10)]\nl","metadata":{"id":"YnM5xI7J_uUt","execution":{"iopub.status.busy":"2023-05-03T20:21:05.051096Z","iopub.execute_input":"2023-05-03T20:21:05.051447Z","iopub.status.idle":"2023-05-03T20:21:05.057569Z","shell.execute_reply.started":"2023-05-03T20:21:05.051419Z","shell.execute_reply":"2023-05-03T20:21:05.056668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ten_pred = torch.tensor(trained_pred)\nten_pred[0].T.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-03T20:30:55.460951Z","iopub.execute_input":"2023-05-03T20:30:55.461653Z","iopub.status.idle":"2023-05-03T20:30:55.488862Z","shell.execute_reply.started":"2023-05-03T20:30:55.461619Z","shell.execute_reply":"2023-05-03T20:30:55.487633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = torch.tensor([[[1,2,3],[1,2,3]], [[1,2,3],[1,2,3]]])\nprint(a.shape)\na = a.repeat(2,1,1)\nprint(a.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T21:21:17.317176Z","iopub.execute_input":"2023-05-03T21:21:17.317894Z","iopub.status.idle":"2023-05-03T21:21:17.324969Z","shell.execute_reply.started":"2023-05-03T21:21:17.317857Z","shell.execute_reply":"2023-05-03T21:21:17.324050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_pred = ten_pred[0].T\nnum=0\nwhile num <10:\n    for i in out_pred[num]:\n        print(int_to_hin[i.item()],end=\"\")\n    print(\"\\n\")\n    num+=1","metadata":{"id":"ic1s-nqVAHFH","execution":{"iopub.status.busy":"2023-05-04T19:39:56.632965Z","iopub.execute_input":"2023-05-04T19:39:56.633363Z","iopub.status.idle":"2023-05-04T19:39:56.644417Z","shell.execute_reply.started":"2023-05-04T19:39:56.633324Z","shell.execute_reply":"2023-05-04T19:39:56.643245Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"#थर्माक्स******************\n\n#सिखाएगा*******************\n\n#लीर्न*********************\n\n#ट्विटर्स******************\n\n#तिरुनेवलेली***************\n\n#इंडेपेंंंस****************\n\n#स्पेशियों*****************\n\n#शुरूह*********************\n\n#कोल्हापुर*****************\n\n#अझर***********************\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in df['eng']:\n  if(len(i) > 24):\n    print(i)","metadata":{"id":"f8o8cuGzAInq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [1,2,3,4]\na.append(0*4)\na","metadata":{"id":"6OpbtU_mARaD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_up","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_pred = torch(tensor(trained_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"pcFlF96qnMGL","outputId":"e3b2efca-866d-4306-daa5-d1d08c047626","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in temp[0]:\n    print(int_to_hin[i.item()], end=\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in temp:\n  for j in i:\n    print(int_to_hin[j.item()], end=\"\")\n  print(\"\\n\")","metadata":{"id":"5ZO63eD6IhUu","outputId":"dccff7a9-a466-4bd1-eb75-b8d6283154a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in zip(tensor_eng, tensor_hin):\n  print(x,y)","metadata":{"id":"SUdsTZzTs3P3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(unique_hin_letters)","metadata":{"id":"X4wZuIxvvGHe","outputId":"bdd4e79e-f8a2-48fd-a672-62f1efda3ae7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [1,2],[3,4]\nb = [1,1],[3,4]\nta = torch.tensor(a)\ntb = torch.tensor(b)\ncalculateAccuracyUPD(a,b)","metadata":{"id":"SK14JJd60Ofz"},"execution_count":null,"outputs":[]}]}