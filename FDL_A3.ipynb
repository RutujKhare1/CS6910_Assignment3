{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport numpy as np\nimport pandas as pd\nimport torch\nimport random\nimport wandb\nimport torch.nn as nn","metadata":{"id":"U2XJa6S3Yk4B","execution":{"iopub.status.busy":"2023-05-10T01:57:12.662139Z","iopub.execute_input":"2023-05-10T01:57:12.662723Z","iopub.status.idle":"2023-05-10T01:57:17.842817Z","shell.execute_reply.started":"2023-05-10T01:57:12.662676Z","shell.execute_reply":"2023-05-10T01:57:17.841605Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device_name = torch.device(\"cuda\")\nelse:\n    device_name = torch.device('cpu')\nprint(\"Using {}.\".format(device_name))","metadata":{"id":"bZG0Efld9B2w","outputId":"66a2b409-d1dc-4fdf-fd62-5692a5c66f9b","execution":{"iopub.status.busy":"2023-05-10T01:58:20.663343Z","iopub.execute_input":"2023-05-10T01:58:20.663743Z","iopub.status.idle":"2023-05-10T01:58:20.727338Z","shell.execute_reply.started":"2023-05-10T01:58:20.663695Z","shell.execute_reply":"2023-05-10T01:58:20.726354Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using cuda.\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocessingData(df):\n    eng_maxlen = len(max(df['eng'], key=len))\n    hin_maxlen = len(max(df['hin'], key=len))\n    max_len = max(eng_maxlen, hin_maxlen)\n    eng_words = df['eng'].copy()\n    for i in range(len(eng_words)):\n        l = len(eng_words[i])\n        eng_words[i] = eng_words[i] + \"*\"*(max_len - l + 3)\n    hin_words = df['hin'].copy()\n    for i in range(len(hin_words)):\n        l = len(hin_words[i])\n        hin_words[i] = \"#\" + hin_words[i] + \"*\"*(max_len - l + 2)\n    unique_eng_letters = set(''.join(eng_words))\n    unique_hin_letters = set(''.join(hin_words))\n    int_to_eng = dict(enumerate(unique_eng_letters))\n    eng_to_int = {char: ind for ind, char in int_to_eng.items()}\n\n    int_to_hin = dict(enumerate(unique_hin_letters))\n    hin_to_int = {char: ind for ind, char in int_to_hin.items()}\n\n    index_eng_words = []\n    for eng_word in eng_words:\n        index_eng_word = [eng_to_int[i] for i in eng_word]\n        index_eng_words.append(index_eng_word)\n    index_hin_words = []\n    for hin_word in hin_words:\n        index_hin_word = [hin_to_int[i] for i in hin_word]\n        index_hin_words.append(index_hin_word)\n    tensor_eng = torch.tensor(index_eng_words).to(device_name)\n    tensor_hin = torch.tensor(index_hin_words).to(device_name)\n    return tensor_eng, tensor_hin, int_to_eng, int_to_hin, unique_eng_letters, unique_hin_letters\n","metadata":{"execution":{"iopub.status.busy":"2023-05-09T16:45:51.969526Z","iopub.execute_input":"2023-05-09T16:45:51.971188Z","iopub.status.idle":"2023-05-09T16:45:51.980747Z","shell.execute_reply.started":"2023-05-09T16:45:51.971157Z","shell.execute_reply":"2023-05-09T16:45:51.979691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GRU_Encoder(nn.Module):\n    def __init__(self, input_size, hid_size, num_of_enc_layers, emb_size, batch_size, dropout, bi_direct):\n        super(GRU_Encoder, self).__init__()\n        self.input_size = input_size\n        self.hid_size = hid_size\n        self.num_of_enc_layers = num_of_enc_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.dropout = dropout\n        self.embedding = nn.Embedding(input_size, emb_size)\n        # print(\"IS:{} ES:{}\".format(input_size, emb_size))\n        self.gru = nn.GRU(emb_size, hid_size, num_of_enc_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden):\n        input_data = input_data.T\n        # print(input_data.shape)\n        embed = self.embedding(input_data).to(device_name)\n        # print(embed.shape,hidden.shape)\n        # embed = embed.view(-1, self.batch_size, self.hid_size)\n        output, hidden = self.gru(embed, hidden)\n        # if(self.bi_direct):\n        #   print(\"bir\\n\")\n        #   hidden = hidden.resize(2, self.num_of_enc_layers, self.batch_size, self.hid_size)\n        #   print(hidden.shape)\n        #   hidden = torch.add(hidden[0], hidden[1])/2\n        #   print(hidden.shape)\n        return output, hidden\n\n    def initialiseHidden(self):\n        if(self.bi_direct):\n            return torch.zeros(2*self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n        else:\n            return torch.zeros(self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n","metadata":{"id":"S4q529z-FjCx","execution":{"iopub.status.busy":"2023-05-10T01:58:25.234081Z","iopub.execute_input":"2023-05-10T01:58:25.234493Z","iopub.status.idle":"2023-05-10T01:58:25.251234Z","shell.execute_reply.started":"2023-05-10T01:58:25.234461Z","shell.execute_reply":"2023-05-10T01:58:25.250294Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class GRU_Decoder(nn.Module):\n    def __init__(self, op_size, num_of_dec_layers, hid_size, batch_size, emb_size, dropout, bi_direct):\n        super(GRU_Decoder, self).__init__()\n        self.op_size = op_size\n        self.hid_size = hid_size\n        self.num_of_dec_layers = num_of_dec_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.embedding = nn.Embedding(op_size, emb_size)\n        self.op = nn.Linear(2*hid_size, op_size) if (bi_direct) else nn.Linear(hid_size, op_size)\n        self.softmax = nn.LogSoftmax(dim = 2)\n        self.gru = nn.GRU(emb_size, hid_size, num_of_dec_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden):\n        # print(input_data)\n        embed = self.embedding(input_data)\n        embed = embed.view(-1, self.batch_size, self.emb_size)\n        #     print(hidden.shape)\n        out, hidden = self.gru(embed, hidden)\n        # print(out.shape)\n        temp = self.op(out)\n        out = self.softmax(temp)\n        return out, hidden","metadata":{"id":"uDr5Mjb6Fi0a","execution":{"iopub.status.busy":"2023-05-10T01:58:26.050350Z","iopub.execute_input":"2023-05-10T01:58:26.051129Z","iopub.status.idle":"2023-05-10T01:58:26.061163Z","shell.execute_reply.started":"2023-05-10T01:58:26.051093Z","shell.execute_reply":"2023-05-10T01:58:26.059514Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class RNN_Encoder(nn.Module):\n    def __init__(self, input_size, hid_size, num_of_enc_layers, emb_size, batch_size, dropout, bi_direct):\n        super(RNN_Encoder, self).__init__()\n        self.input_size = input_size\n        self.hid_size = hid_size\n        self.num_of_enc_layers = num_of_enc_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.dropout = dropout\n        self.embedding = nn.Embedding(input_size, emb_size)\n        self.rnn = nn.RNN(emb_size, hid_size, num_of_enc_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden):\n        input_data = input_data.T\n        embed = self.embedding(input_data).to(device_name)\n        output, hidden = self.rnn(embed, hidden)\n        return output, hidden\n\n    def initialiseHidden(self):\n        if(self.bi_direct):\n            return torch.zeros(2*self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n        else:\n            return torch.zeros(self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-10T01:58:26.812979Z","iopub.execute_input":"2023-05-10T01:58:26.813634Z","iopub.status.idle":"2023-05-10T01:58:26.823218Z","shell.execute_reply.started":"2023-05-10T01:58:26.813598Z","shell.execute_reply":"2023-05-10T01:58:26.821051Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class RNN_Decoder(nn.Module):\n    def __init__(self, op_size, num_of_dec_layers, hid_size, batch_size, emb_size, dropout, bi_direct):\n        super(RNN_Decoder, self).__init__()\n        self.op_size = op_size\n        self.hid_size = hid_size\n        self.num_of_dec_layers = num_of_dec_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.embedding = nn.Embedding(op_size, emb_size)\n        self.op = nn.Linear(2*hid_size, op_size) if (bi_direct) else nn.Linear(hid_size, op_size)\n        self.softmax = nn.LogSoftmax(dim = 2)\n        self.rnn = nn.RNN(emb_size, hid_size, num_of_dec_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden):\n        embed = self.embedding(input_data)\n        embed = embed.view(-1, self.batch_size, self.emb_size)\n        out, hidden = self.rnn(embed, hidden)\n        temp = self.op(out)\n        out = self.softmax(temp)\n        return out, hidden","metadata":{"execution":{"iopub.status.busy":"2023-05-10T01:58:27.316325Z","iopub.execute_input":"2023-05-10T01:58:27.316684Z","iopub.status.idle":"2023-05-10T01:58:27.327067Z","shell.execute_reply.started":"2023-05-10T01:58:27.316653Z","shell.execute_reply":"2023-05-10T01:58:27.326065Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class LSTM_Encoder(nn.Module):\n    def __init__(self, input_size, hid_size, num_of_enc_layers, emb_size, batch_size, dropout, bi_direct):\n        super(LSTM_Encoder, self).__init__()\n        self.input_size = input_size\n        self.hid_size = hid_size\n        self.num_of_enc_layers = num_of_enc_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.dropout = dropout\n        self.embedding = nn.Embedding(input_size, emb_size)\n        self.lstm = nn.LSTM(emb_size, hid_size, num_of_enc_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden, state):\n        input_data = input_data.T\n        embed = self.embedding(input_data).to(device_name)\n        output, (hidden, state) = self.lstm(embed, (hidden, state))\n        return output, hidden, state\n\n    def initialiseHidden(self):\n        if(self.bi_direct):\n            return torch.zeros(2*self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n        else:\n            return torch.zeros(self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-10T01:58:27.820087Z","iopub.execute_input":"2023-05-10T01:58:27.820424Z","iopub.status.idle":"2023-05-10T01:58:27.830526Z","shell.execute_reply.started":"2023-05-10T01:58:27.820397Z","shell.execute_reply":"2023-05-10T01:58:27.829327Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class LSTM_Decoder(nn.Module):\n    def __init__(self, op_size, num_of_dec_layers, hid_size, batch_size, emb_size, dropout, bi_direct):\n        super(LSTM_Decoder, self).__init__()\n        self.op_size = op_size\n        self.hid_size = hid_size\n        self.num_of_dec_layers = num_of_dec_layers\n        self.emb_size = emb_size\n        self.batch_size = batch_size\n        self.bi_direct = bi_direct\n        self.embedding = nn.Embedding(op_size, emb_size)\n        self.op = nn.Linear(2*hid_size, op_size) if (bi_direct) else nn.Linear(hid_size, op_size)\n        self.softmax = nn.LogSoftmax(dim = 2)\n        self.lstm = nn.LSTM(emb_size, hid_size, num_of_dec_layers, bidirectional = bi_direct, dropout = dropout)\n\n    def forward(self, input_data, hidden, state):\n        embed = self.embedding(input_data)\n        embed = embed.view(-1, self.batch_size, self.emb_size)\n        out, (hidden, state) = self.lstm(embed, (hidden, state))\n        temp = self.op(out)\n        out = self.softmax(temp)\n        return out, hidden, state","metadata":{"execution":{"iopub.status.busy":"2023-05-10T01:58:28.358061Z","iopub.execute_input":"2023-05-10T01:58:28.358685Z","iopub.status.idle":"2023-05-10T01:58:28.370890Z","shell.execute_reply.started":"2023-05-10T01:58:28.358649Z","shell.execute_reply":"2023-05-10T01:58:28.369999Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n    teacher_forcing = 0.5\n    loss = 0\n    for b in range(0, len(input_data), batch_size):\n        x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n        temp = 0\n        enc_optimizer.zero_grad()\n        dec_optimizer.zero_grad()\n        if(cell_type == 'GRU' or cell_type == 'RNN'):\n            enc_hidden = encoder.initialiseHidden()\n            enc_output, enc_hidden = encoder(x, enc_hidden)\n            dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_hidden = dec_hidden.repeat(2,1,1)\n            y = y.T\n            dec_input = y[0]\n            #       print(\"AFT_Decoder Hidden : {}\".format(dec_hidden.shape))\n            condition = False if random.random() > teacher_forcing else True\n            if(condition):\n                for i in range(len(y)):\n                    dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n                    temp += loss_fn(torch.squeeze(dec_output), y[i])\n                    dec_input = y[i]\n            else:\n                for i in range(len(y)):\n                    dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n                    prob, idx = dec_output.topk(1)\n                    temp += loss_fn(torch.squeeze(dec_output), y[i])\n                    dec_input = idx\n                    \n        elif(cell_type == 'LSTM'):\n            enc_hidden = encoder.initialiseHidden()\n            enc_state = encoder.initialiseHidden()\n            \n            enc_output, enc_hidden, enc_state = encoder(x, enc_hidden, enc_state)\n            dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_hidden = dec_hidden.repeat(2,1,1)\n            \n            dec_state = enc_state[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_state = dec_state.repeat(2,1,1)\n            y = y.T\n            dec_input = y[0]\n            #       print(\"AFT_Decoder Hidden : {}\".format(dec_hidden.shape))\n            condition = False if random.random() > teacher_forcing else True\n            if(condition):\n                for i in range(len(y)):\n                    dec_output, dec_hidden, dec_state = decoder(dec_input, dec_hidden, dec_state)\n                    temp += loss_fn(torch.squeeze(dec_output), y[i])\n                    dec_input = y[i]\n            else:\n                for i in range(len(y)):\n                    dec_output, dec_hidden, dec_state = decoder(dec_input, dec_hidden, dec_state)\n                    prob, idx = dec_output.topk(1)\n                    temp += loss_fn(torch.squeeze(dec_output), y[i])\n                    dec_input = idx\n        \n        temp.backward()\n        enc_optimizer.step()\n        dec_optimizer.step()\n        loss += temp\n\n    return loss.item()/(len(target_data) * target_data.shape[1]), encoder, decoder\n\n","metadata":{"id":"KToV_mC2WtPI","execution":{"iopub.status.busy":"2023-05-10T01:58:29.988048Z","iopub.execute_input":"2023-05-10T01:58:29.988432Z","iopub.status.idle":"2023-05-10T01:58:30.005871Z","shell.execute_reply.started":"2023-05-10T01:58:29.988401Z","shell.execute_reply":"2023-05-10T01:58:30.005007Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def eval(input_data, target_data, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n    out = []\n    for b in range(0, len(input_data), batch_size):\n        x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n        encoder.eval()\n        decoder.eval()\n        predicted_data = list()\n        if(cell_type == 'GRU' or cell_type == 'RNN'):\n            enc_hidden = encoder.initialiseHidden()\n            enc_output, enc_hidden = encoder(x, enc_hidden)\n            y = y.T      \n            dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n            #dec_hidden = enc_hidden\n            dec_input = y[0]\n            if bi_direct:\n                dec_hidden = dec_hidden.repeat(2,1,1)\n            for i in range(len(y)):\n                dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n                prob, idx = dec_output.topk(1)\n                idx = idx.squeeze()\n                dec_input = idx\n                predicted_data.append(idx.tolist())\n            out.append(predicted_data)\n        elif(cell_type == 'LSTM'):\n            enc_hidden = encoder.initialiseHidden()\n            enc_state = encoder.initialiseHidden()\n            enc_output, enc_hidden, enc_state = encoder(x, enc_hidden, enc_state)\n            y = y.T      \n            dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_hidden = dec_hidden.repeat(2,1,1)\n                \n            dec_state = enc_state[-1].repeat(num_of_dec_layers, 1, 1)\n            if bi_direct:\n                dec_state = dec_state.repeat(2,1,1)\n            \n            dec_input = y[0]\n            for i in range(len(y)):\n                dec_output, dec_hidden, dec_state = decoder(dec_input, dec_hidden, dec_state)\n                prob, idx = dec_output.topk(1)\n                idx = idx.squeeze()\n                dec_input = idx\n                predicted_data.append(idx.tolist())\n            out.append(predicted_data)\n    return out","metadata":{"id":"tosOCKpmU49G","execution":{"iopub.status.busy":"2023-05-10T01:58:33.080302Z","iopub.execute_input":"2023-05-10T01:58:33.080657Z","iopub.status.idle":"2023-05-10T01:58:33.096480Z","shell.execute_reply.started":"2023-05-10T01:58:33.080628Z","shell.execute_reply":"2023-05-10T01:58:33.095507Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# def eval(input_data, target_data, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n#     out = []\n#   for b in range(0, len(input_data), batch_size):\n#     x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n#     encoder.eval()\n#     decoder.eval()\n#     predicted_data = list()\n#     if(cell_type == 'GRU'):\n#       enc_hidden = encoder.initialiseHidden()\n#       enc_output, enc_hidden = encoder(x, enc_hidden)\n#       y = y.T      \n#       dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n#       #dec_hidden = enc_hidden\n#       dec_input = y[0]\n#       if bi_direct:\n#             dec_hidden = dec_hidden.repeat(2,1,1)\n#       for i in range(len(y)):\n#         dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n#         prob, idx = dec_output.topk(1)\n#         idx = idx.squeeze()\n#         dec_input = idx\n#         predicted_data.append(idx.tolist())\n#       out.append(predicted_data)\n#   return out","metadata":{"execution":{"iopub.status.busy":"2023-05-10T01:58:34.154762Z","iopub.execute_input":"2023-05-10T01:58:34.156056Z","iopub.status.idle":"2023-05-10T01:58:34.162285Z","shell.execute_reply.started":"2023-05-10T01:58:34.156009Z","shell.execute_reply":"2023-05-10T01:58:34.160960Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# def training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size):\n#   learning_rate = 0.001\n#   if(cell_type == \"GRU\"):\n#     encoder = GRU_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n#     decoder = GRU_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n#   elif(cell_typ == \"RNN\"):\n#     encoder = RNN_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n#     decoder = RNN_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n  \n#   enc_optimizer = torch.optim.Adam(encoder.parameters(), learning_rate)\n#   dec_optimizer = torch.optim.Adam(decoder.parameters(), learning_rate)\n#   loss_fn = nn.CrossEntropyLoss(reduction = 'sum')\n#   encoder.train()\n#   decoder.train()\n#   loss_list = []\n#   for i in range(epochs):\n#     loss, encoder, decoder = train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\n#     loss_list.append(loss/51200)\n#     print(\"Epoch : {} \\tLoss : {}\".format(i, loss))\n\n#   return encoder, decoder, num_of_enc_layers, num_of_dec_layers\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T01:58:34.750568Z","iopub.execute_input":"2023-05-10T01:58:34.750951Z","iopub.status.idle":"2023-05-10T01:58:34.756264Z","shell.execute_reply.started":"2023-05-10T01:58:34.750922Z","shell.execute_reply":"2023-05-10T01:58:34.755230Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# def train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type):\n#     teacher_forcing = 0.5\n#     loss = 0\n#     for b in range(0, len(input_data), batch_size):\n#         x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n#         temp = 0\n#         enc_optimizer.zero_grad()\n#         dec_optimizer.zero_grad()\n#         if(cell_type == 'GRU' or cell_type == 'RNN'):\n#             enc_hidden = encoder.initialiseHidden()\n#             enc_output, enc_hidden = encoder(x, enc_hidden)\n#             #       print(\"AFT_Encoder Hidden : {}\".format(enc_hidden.shape))\n#             #       if(num_of_dec_layers > num_of_enc_layers):\n#             # #         print(\"1\")\n#             #         num = num_of_dec_layers-2\n#             #         dec_hidden = enc_hidden\n#             #         while(num != num_of_enc_layers):\n#             #           dec_hidden = torch.cat([dec_hidden, enc_hidden[-1].unsqueeze(0)], dim = 0)\n#             #           num -= 1\n#             #       elif(num_of_dec_layers < num_of_enc_layers):\n#             # #         print(\"2\")\n#             #         dec_hidden = enc_hidden[-num_of_dec_layers:]\n#             #       else:\n#             # #         print(\"3\")\n#             #         dec_hidden = enc_hidden\n#             dec_hidden = enc_hidden[-1].repeat(num_of_dec_layers, 1, 1)\n#             #dec_hidden = enc_hidden\n#             if bi_direct:\n#                 dec_hidden = dec_hidden.repeat(2,1,1)\n#             y = y.T\n#             dec_input = y[0]\n#             #       print(\"AFT_Decoder Hidden : {}\".format(dec_hidden.shape))\n#             condition = False if random.random() > teacher_forcing else True\n#             if(condition):\n#                 for i in range(len(y)):\n#                     dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n#                     temp += loss_fn(torch.squeeze(dec_output), y[i])\n#                     dec_input = y[i]\n#             else:\n#                 for i in range(len(y)):\n#                     dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n#                     prob, idx = dec_output.topk(1)\n#                     temp += loss_fn(torch.squeeze(dec_output), y[i])\n#                     dec_input = idx\n#             temp.backward()\n#             enc_optimizer.step()\n#             dec_optimizer.step()\n#             loss += temp\n\n#     return loss.item()/(len(target_data) * target_data.shape[1]), encoder, decoder\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T01:58:35.311740Z","iopub.execute_input":"2023-05-10T01:58:35.312309Z","iopub.status.idle":"2023-05-10T01:58:35.318477Z","shell.execute_reply.started":"2023-05-10T01:58:35.312274Z","shell.execute_reply":"2023-05-10T01:58:35.317402Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size):\n    learning_rate = 0.001\n    if(cell_type == \"GRU\"):\n        encoder = GRU_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n        decoder = GRU_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n    elif(cell_type == \"RNN\"):\n        encoder = RNN_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n        decoder = RNN_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n    elif(cell_type == \"LSTM\"):\n        encoder = LSTM_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, enc_dropout, bi_direct).to(device_name)\n        decoder = LSTM_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, dec_dropout, bi_direct).to(device_name)\n\n    enc_optimizer = torch.optim.Adam(encoder.parameters(), learning_rate)\n    dec_optimizer = torch.optim.Adam(decoder.parameters(), learning_rate)\n    loss_fn = nn.NLLLoss(reduction = 'sum')\n    encoder.train()\n    decoder.train()\n    loss_list = []\n    for i in range(epochs):\n        loss, encoder, decoder = train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\n        loss_list.append(loss)\n        print(\"Epoch : {} \\tLoss : {}\".format(i, loss))\n\n    return encoder, decoder, num_of_enc_layers, num_of_dec_layers, loss_list\n","metadata":{"id":"ifkAGoezFiwH","execution":{"iopub.status.busy":"2023-05-10T02:25:54.995591Z","iopub.execute_input":"2023-05-10T02:25:54.995962Z","iopub.status.idle":"2023-05-10T02:25:55.007675Z","shell.execute_reply.started":"2023-05-10T02:25:54.995931Z","shell.execute_reply":"2023-05-10T02:25:55.006747Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:56.197188Z","iopub.execute_input":"2023-05-09T17:35:56.197547Z","iopub.status.idle":"2023-05-09T17:35:56.203069Z","shell.execute_reply.started":"2023-05-09T17:35:56.197516Z","shell.execute_reply":"2023-05-09T17:35:56.201953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/fdl-a3/hin_train.csv', names=['eng','hin'])\ntensor_eng, tensor_hin, int_to_eng, int_to_hin, unique_eng_letters, unique_hin_letters = preprocessingData(df)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:35:57.671069Z","iopub.execute_input":"2023-05-09T17:35:57.671438Z","iopub.status.idle":"2023-05-09T17:35:59.793952Z","shell.execute_reply.started":"2023-05-09T17:35:57.671407Z","shell.execute_reply":"2023-05-09T17:35:59.793015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data = tensor_eng\ninput_size = len(unique_eng_letters)\ntarget_data = tensor_hin\ntarget_size = len(unique_hin_letters) \nmax_input_size = tensor_eng.shape[1] \nepochs = 7\nbatch_size = 64 \nemb_size = 256 \nnum_of_enc_layers = 1\nnum_of_dec_layers = 3\nhid_size = 256\ncell_type = \"LSTM\" \nbi_direct = True \nenc_dropout = 0.3\ndec_dropout = 0.3 \nbeam_size = 1","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:36:02.780109Z","iopub.execute_input":"2023-05-09T17:36:02.780548Z","iopub.status.idle":"2023-05-09T17:36:02.791368Z","shell.execute_reply.started":"2023-05-09T17:36:02.780511Z","shell.execute_reply":"2023-05-09T17:36:02.790500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder, decoder, num_of_enc_layers, num_of_dec_layers = training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size)","metadata":{"id":"Us7xCAvmwhbE","outputId":"2a475a4b-106d-4958-f7bc-f1df04d947cf","execution":{"iopub.status.busy":"2023-05-09T17:36:03.402749Z","iopub.execute_input":"2023-05-09T17:36:03.403091Z","iopub.status.idle":"2023-05-09T17:42:14.636786Z","shell.execute_reply.started":"2023-05-09T17:36:03.403062Z","shell.execute_reply":"2023-05-09T17:42:14.635674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_pred = eval(tensor_eng, tensor_hin, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)","metadata":{"id":"9kejVozOEl_o","execution":{"iopub.status.busy":"2023-05-09T17:42:19.404877Z","iopub.execute_input":"2023-05-09T17:42:19.405243Z","iopub.status.idle":"2023-05-09T17:42:35.531434Z","shell.execute_reply.started":"2023-05-09T17:42:19.405212Z","shell.execute_reply":"2023-05-09T17:42:35.530489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.tensor(trained_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T17:42:35.533496Z","iopub.execute_input":"2023-05-09T17:42:35.533871Z","iopub.status.idle":"2023-05-09T17:42:35.799831Z","shell.execute_reply.started":"2023-05-09T17:42:35.533837Z","shell.execute_reply":"2023-05-09T17:42:35.798767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = []\nten_pred = torch.tensor(trained_pred)\nfor i in range(len(trained_pred)):\n    temp = ten_pred[i].T\n    out.extend(temp)\nout_pred = torch.stack(out).to(device_name)\nprint(calculateAccuracy(out_pred, tensor_hin))","metadata":{"id":"LyHQWp5kI_gP","execution":{"iopub.status.busy":"2023-05-09T17:42:45.190958Z","iopub.execute_input":"2023-05-09T17:42:45.191313Z","iopub.status.idle":"2023-05-09T17:42:48.112184Z","shell.execute_reply.started":"2023-05-09T17:42:45.191282Z","shell.execute_reply":"2023-05-09T17:42:48.111178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/fdl-a3/hin_test.csv', names=['eng','hin'])\n\neng_words = df_test['eng'].copy()\nfor i in range(len(eng_words)):\n    l = len(eng_words[i])\n    eng_words[i] = eng_words[i] + \"*\"*(24 - l + 3)\nhin_words = df_test['hin'].copy()\nfor i in range(len(hin_words)):\n    l = len(hin_words[i])\n    hin_words[i] = \"#\" + hin_words[i] + \"*\"*(24 - l + 2)\n    \neng_to_int = {v: k for k, v in int_to_eng.items()}\nhin_to_int = {v: k for k, v in int_to_hin.items()}\n","metadata":{"id":"g7cyXu1OcIx0","outputId":"b6f77907-8198-49c8-eb4e-3946b47637d8","execution":{"iopub.status.busy":"2023-05-09T17:42:52.714662Z","iopub.execute_input":"2023-05-09T17:42:52.715045Z","iopub.status.idle":"2023-05-09T17:42:52.843335Z","shell.execute_reply.started":"2023-05-09T17:42:52.715011Z","shell.execute_reply":"2023-05-09T17:42:52.842502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_eng_words = []\nfor eng_word in eng_words:\n    index_eng_word = [eng_to_int[i] for i in eng_word]\n    index_eng_words.append(index_eng_word)\nindex_hin_words = []\nfor hin_word in hin_words:\n    index_hin_word = [hin_to_int[i] if i in hin_to_int else hin_to_int['_'] for i in hin_word]\n    index_hin_words.append(index_hin_word)\n\ntensor_eng_test = torch.tensor(index_eng_words).to(device_name)\ntensor_hin_test = torch.tensor(index_hin_words).to(device_name)\n\ntrained_pred = eval(tensor_eng_test, tensor_hin_test, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\nout = []\nten_pred = torch.tensor(trained_pred)\nfor i in range(len(trained_pred)):\n    temp = ten_pred[i].T\n    out.extend(temp)\nout_pred = torch.stack(out).to(device_name)\nprint(calculateAccuracy(out_pred, tensor_hin_test))","metadata":{"id":"4kA10NUNLaqR","outputId":"21a4d7a9-0f74-4650-c6d5-8877cdef6f92","execution":{"iopub.status.busy":"2023-05-09T17:42:54.327414Z","iopub.execute_input":"2023-05-09T17:42:54.327791Z","iopub.status.idle":"2023-05-09T17:42:55.985000Z","shell.execute_reply.started":"2023-05-09T17:42:54.327748Z","shell.execute_reply":"2023-05-09T17:42:55.983812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UPDATION!!!","metadata":{}},{"cell_type":"code","source":"def preprocessingDataUPD(df, max_len, eng_to_int, hin_to_int):\n    eng_words = df['eng'].copy()\n    for i in range(len(eng_words)):\n        l = len(eng_words[i])\n        eng_words[i] = eng_words[i] + \"*\"*(max_len - l + 3)\n    hin_words = df['hin'].copy()\n    for i in range(len(hin_words)):\n        l = len(hin_words[i])\n        hin_words[i] = \"#\" + hin_words[i] + \"*\"*(max_len - l + 2)\n\n    index_eng_words = []\n    for eng_word in eng_words:\n        index_eng_word = [eng_to_int[i] for i in eng_word]\n        index_eng_words.append(index_eng_word)\n    index_hin_words = []\n    for hin_word in hin_words:\n        index_hin_word = [hin_to_int[i] if i in hin_to_int else hin_to_int['_'] for i in hin_word]\n        index_hin_words.append(index_hin_word)\n    tensor_eng = torch.tensor(index_eng_words).to(device_name)\n    tensor_hin = torch.tensor(index_hin_words).to(device_name)\n    return tensor_eng, tensor_hin\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:13:17.937207Z","iopub.execute_input":"2023-05-10T02:13:17.937581Z","iopub.status.idle":"2023-05-10T02:13:17.949595Z","shell.execute_reply.started":"2023-05-10T02:13:17.937552Z","shell.execute_reply":"2023-05-10T02:13:17.948277Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def calculateAccuracyUPD(trained_pred, y_true):\n    out = []\n    ten_pred = torch.tensor(trained_pred)\n    for i in range(len(trained_pred)):\n        temp = ten_pred[i].T\n        out.extend(temp)\n    y_pred = torch.stack(out).to(device_name)\n    cnt = 0\n    for i,j in zip(y_pred, y_true):\n        cor = torch.eq(i, j)\n        if(torch.mean(cor.float()).item() == 1.0):\n            cnt += 1\n    return cnt / len(y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:13:21.875497Z","iopub.execute_input":"2023-05-10T02:13:21.875881Z","iopub.status.idle":"2023-05-10T02:13:21.885291Z","shell.execute_reply.started":"2023-05-10T02:13:21.875836Z","shell.execute_reply":"2023-05-10T02:13:21.884277Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/fdl-a3/hin_train.csv', names=['eng','hin'])\ndf_test = pd.read_csv('/kaggle/input/fdl-a3/hin_test.csv', names=['eng','hin'])\neng_maxlen = len(max(df['eng'], key=len))\nhin_maxlen = len(max(df['hin'], key=len))\nmax_len = max(eng_maxlen, hin_maxlen)\neng_words = df['eng'].copy()\nhin_words = df['hin'].copy()\n\nunique_eng_letters = set(''.join(eng_words))\nunique_eng_letters.add('*')\n\nunique_hin_letters = set(''.join(hin_words))\nunique_hin_letters.add('#')\nunique_hin_letters.add('*')\n\nint_to_eng = dict(enumerate(unique_eng_letters))\neng_to_int = {char: ind for ind, char in int_to_eng.items()}\n\nint_to_hin = dict(enumerate(unique_hin_letters))\nhin_to_int = {char: ind for ind, char in int_to_hin.items()}\nhin_to_int['_'] = len(hin_to_int)\n\ntensor_eng, tensor_hin = preprocessingDataUPD(df, max_len, eng_to_int, hin_to_int)\ntensor_eng_test, tensor_hin_test = preprocessingDataUPD(df_test, max_len, eng_to_int, hin_to_int)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:13:22.564550Z","iopub.execute_input":"2023-05-10T02:13:22.565217Z","iopub.status.idle":"2023-05-10T02:13:26.474257Z","shell.execute_reply.started":"2023-05-10T02:13:22.565176Z","shell.execute_reply":"2023-05-10T02:13:26.473244Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"input_data = tensor_eng\ninput_size = len(unique_eng_letters)\ntarget_data = tensor_hin\ntarget_size = len(unique_hin_letters) \nmax_input_size = tensor_eng.shape[1] \nepochs = 7\nbatch_size = 64 \nemb_size = 256 \nnum_of_enc_layers = 1\nnum_of_dec_layers = 3\nhid_size = 256\ncell_type = \"LSTM\" \nbi_direct = True \nenc_dropout = 0.3\ndec_dropout = 0.3 \nbeam_size = 1","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:13:29.857571Z","iopub.execute_input":"2023-05-10T02:13:29.857960Z","iopub.status.idle":"2023-05-10T02:13:29.863848Z","shell.execute_reply.started":"2023-05-10T02:13:29.857927Z","shell.execute_reply":"2023-05-10T02:13:29.862927Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"encoder, decoder, num_of_enc_layers, num_of_dec_layers, loss_list = training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size)\ntrained_pred = eval(tensor_eng, tensor_hin, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\ncalculateAccuracyUPD(trained_pred, tensor_hin)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:13:34.746470Z","iopub.execute_input":"2023-05-10T02:13:34.746815Z","iopub.status.idle":"2023-05-10T02:20:27.053833Z","shell.execute_reply.started":"2023-05-10T02:13:34.746787Z","shell.execute_reply":"2023-05-10T02:20:27.052807Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 0 \tLoss : 0.5918397804542824\nEpoch : 1 \tLoss : 0.33685739022714123\nEpoch : 2 \tLoss : 0.29182411476417824\nEpoch : 3 \tLoss : 0.2602344428168403\nEpoch : 4 \tLoss : 0.2384947826244213\nEpoch : 5 \tLoss : 0.22785886411313658\nEpoch : 6 \tLoss : 0.21027095088252315\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.45375"},"metadata":{}}]},{"cell_type":"code","source":"trained_pred = eval(tensor_eng_test, tensor_hin_test, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\ncalculateAccuracyUPD(trained_pred, tensor_hin_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:20:51.128101Z","iopub.execute_input":"2023-05-10T02:20:51.128514Z","iopub.status.idle":"2023-05-10T02:20:53.064881Z","shell.execute_reply.started":"2023-05-10T02:20:51.128483Z","shell.execute_reply":"2023-05-10T02:20:53.063821Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0.3251953125"},"metadata":{}}]},{"cell_type":"markdown","source":"# SWEEP CONFIG","metadata":{}},{"cell_type":"code","source":"def sweepTrain():\n    input_data = tensor_eng\n    input_size = len(unique_eng_letters)\n    target_data = tensor_hin\n    target_size = len(unique_hin_letters) \n    max_input_size = tensor_eng.shape[1] \n    epochs = 7\n    batch_size = 64 \n    emb_size = 256 \n    num_of_enc_layers = 1\n    num_of_dec_layers = 3\n    hid_size = 256\n    cell_type = \"LSTM\" \n    bi_direct = True \n    enc_dropout = 0.3\n    dec_dropout = 0.3 \n    beam_size = 1\n    \n    encoder, decoder, num_of_enc_layers, num_of_dec_layers = training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, enc_dropout, dec_dropout, beam_size)\n    trained_pred = eval(tensor_eng, tensor_hin, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\n    calculateAccuracyUPD(trained_pred, tensor_hin)\n    trained_pred = eval(tensor_eng_test, tensor_hin_test, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, bi_direct, cell_type)\n    calculateAccuracyUPD(trained_pred, tensor_hin_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Experimental Area**","metadata":{"id":"6h-qHdB__elc"}},{"cell_type":"code","source":"l = [i if i!=5 else 99 for i in range(10)]\nl","metadata":{"id":"YnM5xI7J_uUt","execution":{"iopub.status.busy":"2023-05-03T20:21:05.051096Z","iopub.execute_input":"2023-05-03T20:21:05.051447Z","iopub.status.idle":"2023-05-03T20:21:05.057569Z","shell.execute_reply.started":"2023-05-03T20:21:05.051419Z","shell.execute_reply":"2023-05-03T20:21:05.056668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ten_pred = torch.tensor(trained_pred)\nten_pred[0].T.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-03T20:30:55.460951Z","iopub.execute_input":"2023-05-03T20:30:55.461653Z","iopub.status.idle":"2023-05-03T20:30:55.488862Z","shell.execute_reply.started":"2023-05-03T20:30:55.461619Z","shell.execute_reply":"2023-05-03T20:30:55.487633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = torch.tensor([[[1,2,3],[1,2,3]], [[1,2,3],[1,2,3]]])\nprint(a.shape)\na = a.repeat(2,1,1)\nprint(a.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T21:21:17.317176Z","iopub.execute_input":"2023-05-03T21:21:17.317894Z","iopub.status.idle":"2023-05-03T21:21:17.324969Z","shell.execute_reply.started":"2023-05-03T21:21:17.317857Z","shell.execute_reply":"2023-05-03T21:21:17.324050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_pred = ten_pred[0].T\nnum=0\nwhile num <10:\n    for i in out_pred[num]:\n        print(int_to_hin[i.item()],end=\"\")\n    print(\"\\n\")\n    num+=1","metadata":{"id":"ic1s-nqVAHFH","execution":{"iopub.status.busy":"2023-05-04T19:39:56.632965Z","iopub.execute_input":"2023-05-04T19:39:56.633363Z","iopub.status.idle":"2023-05-04T19:39:56.644417Z","shell.execute_reply.started":"2023-05-04T19:39:56.633324Z","shell.execute_reply":"2023-05-04T19:39:56.643245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df['eng']:\n  if(len(i) > 24):\n    print(i)","metadata":{"id":"f8o8cuGzAInq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [1,2,3,4]\na.append(0*4)\na","metadata":{"id":"6OpbtU_mARaD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_up","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_pred = torch(tensor(trained_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"pcFlF96qnMGL","outputId":"e3b2efca-866d-4306-daa5-d1d08c047626","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in temp[0]:\n    print(int_to_hin[i.item()], end=\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in temp:\n  for j in i:\n    print(int_to_hin[j.item()], end=\"\")\n  print(\"\\n\")","metadata":{"id":"5ZO63eD6IhUu","outputId":"dccff7a9-a466-4bd1-eb75-b8d6283154a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in zip(tensor_eng, tensor_hin):\n  print(x,y)","metadata":{"id":"SUdsTZzTs3P3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(unique_hin_letters)","metadata":{"id":"X4wZuIxvvGHe","outputId":"bdd4e79e-f8a2-48fd-a672-62f1efda3ae7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [1,2],[3,4]\nb = [1,1],[3,4]\nta = torch.tensor(a)\ntb = torch.tensor(b)\ncalculateAccuracyUPD(a,b)","metadata":{"id":"SK14JJd60Ofz"},"execution_count":null,"outputs":[]}]}