{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hWD2qa_DQt8gAoz15e9AibGeIQsuwXH_",
      "authorship_tag": "ABX9TyO3Sd+BYJg5YBEIY5Nb9VJb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RutujKhare1/CS6910_Assignment3/blob/main/FDL_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "0nunHnybCpgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4475a1-4dad-4ae0-abbf-af4c4df95257"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.21.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "P0EEiw_RlOn4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U2XJa6S3Yk4B"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "else:\n",
        "    device_name = torch.device('cpu')\n",
        "print(\"Using {}.\".format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZG0Efld9B2w",
        "outputId": "ba8363cc-84a9-412e-c303-ee9c61b5d27d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/FDL_A3/hin/hin_train.csv', names=['eng','hin'])"
      ],
      "metadata": {
        "id": "6srSwMqgClUB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_words = df['eng'].copy()\n",
        "eng_maxlen = len(max(df['eng'], key=len))\n",
        "for i in range(len(eng_words)):\n",
        "  l = len(eng_words[i])\n",
        "  eng_words[i] = eng_words[i] + \"*\"*(eng_maxlen - l + 2)"
      ],
      "metadata": {
        "id": "U60nMHdVRGEw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hin_words = df['hin'].copy()\n",
        "hin_maxlen = len(max(df['hin'], key=len))\n",
        "for i in range(len(hin_words)):\n",
        "  l = len(hin_words[i])\n",
        "  hin_words[i] = \"#\" + hin_words[i] + \"*\"*(hin_maxlen - l + 2)"
      ],
      "metadata": {
        "id": "byPgiy6fVqfq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_eng_letters = set(''.join(eng_words))\n",
        "unique_hin_letters = set(''.join(hin_words))\n",
        "int_to_eng = dict(enumerate(unique_eng_letters))\n",
        "eng_to_int = {char: ind for ind, char in int_to_eng.items()}\n",
        "\n",
        "int_to_hin = dict(enumerate(unique_hin_letters))\n",
        "hin_to_int = {char: ind for ind, char in int_to_hin.items()}"
      ],
      "metadata": {
        "id": "-QBfA5AnqbdH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_eng_words = []\n",
        "for eng_word in eng_words:\n",
        "  index_eng_word = [eng_to_int[i] for i in eng_word]\n",
        "  index_eng_words.append(index_eng_word)"
      ],
      "metadata": {
        "id": "u36AijnMRBbB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_hin_words = []\n",
        "for hin_word in hin_words:\n",
        "  index_hin_word = [hin_to_int[i] for i in hin_word]\n",
        "  index_hin_words.append(index_hin_word)"
      ],
      "metadata": {
        "id": "vBUP1K6jolVb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_eng = torch.tensor(index_eng_words).to(device_name)\n",
        "tensor_hin = torch.tensor(index_hin_words).to(device_name)\n",
        "tensor_hin"
      ],
      "metadata": {
        "id": "BaHcaexBFjO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c3c8c0-d4d1-402c-c04d-b1a6c5d64414"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[62, 57, 14,  ..., 40, 40, 40],\n",
              "        [62, 17, 42,  ..., 40, 40, 40],\n",
              "        [62, 23, 42,  ..., 40, 40, 40],\n",
              "        ...,\n",
              "        [62, 21, 14,  ..., 40, 40, 40],\n",
              "        [62, 14, 65,  ..., 40, 40, 40],\n",
              "        [62, 21, 39,  ..., 40, 40, 40]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hid_size, num_of_enc_layers, emb_size, batch_size, bi_direct):\n",
        "    super(GRU_Encoder, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hid_size = hid_size\n",
        "    self.num_of_enc_layers = num_of_enc_layers\n",
        "    self.emb_size = emb_size\n",
        "    self.batch_size = batch_size\n",
        "    self.bi_direct = bi_direct\n",
        "    self.embedding = nn.Embedding(input_size, emb_size)\n",
        "    # print(\"IS:{} ES:{}\".format(input_size, emb_size))\n",
        "    self.gru = nn.GRU(emb_size, hid_size, num_of_enc_layers, bidirectional = bi_direct)\n",
        "\n",
        "  def forward(self, input_data, hidden):\n",
        "    # print(input_data.shape)\n",
        "    embed = self.embedding(input_data).to(device_name)\n",
        "    # print(embed.shape)\n",
        "    embed = embed.view(-1, self.batch_size, self.hid_size)\n",
        "    output, hidden = self.gru(embed, hidden)\n",
        "    if(self.bi_direct):\n",
        "      hidden = hidden.resize(2, self.num_of_enc_layers, self.batch_size, self.hid_size)\n",
        "      hidden = torch.add(hidden[0], hidden[1])/2\n",
        "    return output, hidden\n",
        "  \n",
        "  def initialiseHidden(self):\n",
        "    if(self.bi_direct):\n",
        "      return torch.zeros(2*self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n",
        "    else:\n",
        "      return torch.zeros(self.num_of_enc_layers, self.batch_size, self.hid_size, device = device_name)\n",
        "  "
      ],
      "metadata": {
        "id": "S4q529z-FjCx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_Decoder(nn.Module):\n",
        "  def __init__(self, op_size, num_of_dec_layers, hid_size, batch_size, emb_size, bi_direct):\n",
        "    super(GRU_Decoder, self).__init__()\n",
        "    self.op_size = op_size\n",
        "    self.hid_size = hid_size\n",
        "    self.num_of_dec_layers = num_of_dec_layers\n",
        "    self.emb_size = emb_size\n",
        "    self.batch_size = batch_size\n",
        "    self.bi_direct = bi_direct\n",
        "    self.embedding = nn.Embedding(op_size, emb_size)\n",
        "    self.op = nn.Linear(hid_size, op_size)\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "    self.gru = nn.GRU(emb_size, hid_size, num_of_dec_layers, bidirectional = bi_direct)\n",
        "\n",
        "  def forward(self, input_data, hidden):\n",
        "    # print(input_data)\n",
        "    embed = self.embedding(input_data)\n",
        "    embed = embed.view(-1, self.batch_size, self.emb_size)\n",
        "    out, hidden = self.gru(embed, hidden)\n",
        "    out = self.softmax(self.op(out))\n",
        "    return out, hidden"
      ],
      "metadata": {
        "id": "uDr5Mjb6Fi0a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, cell_type):\n",
        "  teacher_forcing = 0.5\n",
        "  loss = 0\n",
        "  for b in range(0, len(input_data), batch_size):\n",
        "    x, y = input_data[b : b+batch_size], target_data[b : b+batch_size]\n",
        "    temp = 0\n",
        "    enc_optimizer.zero_grad()\n",
        "    dec_optimizer.zero_grad()\n",
        "    # x = x.T\n",
        "    # y = y.T\n",
        "    t_step = len(x)\n",
        "    if(cell_type == 'GRU'):\n",
        "      enc_hidden = encoder.initialiseHidden()\n",
        "      enc_output, enc_hidden = encoder(x, enc_hidden)\n",
        "      \n",
        "      if(num_of_dec_layers > num_of_enc_layers):\n",
        "        num = num_of_dec_layers\n",
        "        dec_hidden = enc_hidden\n",
        "        while(num != num_of_enc_layers):\n",
        "          dec_hidden = torch.cat([dec_hidden, enc_hidden[-1].unsqueeze(0)], dim = 0)\n",
        "          num -= 1\n",
        "      elif(num_of_dec_layers < num_of_enc_layers):\n",
        "        dec_hidden = enc_hidden[-num_of_dec_layers:]\n",
        "      else:\n",
        "        dec_hidden = enc_hidden\n",
        "      y = y.T\n",
        "      dec_input = y[0]\n",
        "      condition = False if random.random() > teacher_forcing else True\n",
        "      if(condition):\n",
        "        for i in range(1,len(y)):\n",
        "          dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n",
        "          temp += loss_fn(torch.squeeze(dec_output), y[i])\n",
        "          dec_input = y[i]\n",
        "      else:\n",
        "        for i in range(1,len(y)):\n",
        "          dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n",
        "          prob, idx = dec_output.topk(1)\n",
        "          temp += loss_fn(torch.squeeze(dec_output), y[i])\n",
        "          dec_input = idx\n",
        "    temp.backward()\n",
        "    enc_optimizer.step()\n",
        "    dec_optimizer.step()\n",
        "    loss += temp\n",
        "  # print(len(target_data))\n",
        "  return loss.item() / len(target_data), encoder, decoder\n",
        "\n"
      ],
      "metadata": {
        "id": "KToV_mC2WtPI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(input_data, target_data, encoder, decoder, num_of_enc_layers, num_of_dec_layers, cell_type):\n",
        "  x, y = input_data, target_data\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "  predicted_data = list()\n",
        "  # x = x.T\n",
        "  # y = y.T\n",
        "  t_step = len(x)\n",
        "  if(cell_type == 'GRU'):\n",
        "    enc_hidden = encoder.initialiseHidden()\n",
        "    enc_output, enc_hidden = encoder(x, enc_hidden)\n",
        "    \n",
        "    if(num_of_dec_layers > num_of_enc_layers):\n",
        "      num = num_of_dec_layers\n",
        "      dec_hidden = enc_hidden\n",
        "      while(num != num_of_enc_layers):\n",
        "        dec_hidden = torch.cat([dec_hidden, enc_hidden[-1].unsqueeze(0)], dim = 0)\n",
        "        num -= 1\n",
        "    elif(num_of_dec_layers < num_of_enc_layers):\n",
        "      dec_hidden = enc_hidden[-num_of_dec_layers:]\n",
        "    else:\n",
        "      dec_hidden = enc_hidden\n",
        "    y = y.T\n",
        "    dec_input = y[0]\n",
        "\n",
        "    for i in range(len(y)):\n",
        "      dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n",
        "      prob, idx = dec_output.topk(1)\n",
        "      idx = idx.squeeze()\n",
        "      dec_input = idx\n",
        "      predicted_data.append(idx.tolist())\n",
        "  return predicted_data\n"
      ],
      "metadata": {
        "id": "tosOCKpmU49G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(input_data, input_size, target_data, target_size, max_input_size, epochs, batch_size, emb_size, num_of_enc_layers, num_of_dec_layers, hid_size, cell_type, bi_direct, dropout, beam_size):\n",
        "  learning_rate = 0.001\n",
        "  if(cell_type == \"GRU\"):\n",
        "    encoder = GRU_Encoder(input_size, hid_size, num_of_enc_layers, emb_size, batch_size, bi_direct).to(device_name)\n",
        "    decoder = GRU_Decoder(target_size, num_of_dec_layers, hid_size, batch_size, emb_size, bi_direct).to(device_name)\n",
        "  \n",
        "  enc_optimizer = torch.optim.Adam(encoder.parameters(), learning_rate)\n",
        "  dec_optimizer = torch.optim.Adam(decoder.parameters(), learning_rate)\n",
        "  loss_fn = nn.CrossEntropyLoss(reduction = 'sum')\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "  loss_list = []\n",
        "  for i in range(epochs):\n",
        "    loss, encoder, decoder = train(input_data, target_data, loss_fn, enc_optimizer, dec_optimizer, encoder, decoder, num_of_enc_layers, num_of_dec_layers, batch_size, cell_type)\n",
        "    loss_list.append(loss/51200)\n",
        "    print(loss)\n",
        "\n",
        "  return encoder, decoder, num_of_enc_layers, num_of_dec_layers\n"
      ],
      "metadata": {
        "id": "ifkAGoezFiwH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder, decoder, num_of_enc_layers, num_of_dec_layers = training(input_data = tensor_eng, \n",
        "                                                                  input_size = len(unique_eng_letters), \n",
        "                                                                  target_data = tensor_hin, \n",
        "                                                                  target_size = len(unique_hin_letters), \n",
        "                                                                  max_input_size = 24, \n",
        "                                                                  epochs = 10, \n",
        "                                                                  batch_size = 32, \n",
        "                                                                  emb_size = 64, \n",
        "                                                                  num_of_enc_layers = 2, \n",
        "                                                                  num_of_dec_layers = 2, \n",
        "                                                                  hid_size = 64, \n",
        "                                                                  cell_type = \"GRU\", \n",
        "                                                                  bi_direct = False, \n",
        "                                                                  dropout = 0.2, \n",
        "                                                                  beam_size = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us7xCAvmwhbE",
        "outputId": "2188cdf5-4b64-4a9a-b14b-22e08e277aea"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51200\n",
            "39.156083984375\n",
            "51200\n",
            "32.2370068359375\n",
            "51200\n",
            "31.3527392578125\n",
            "51200\n",
            "31.0369921875\n",
            "51200\n",
            "30.93255615234375\n",
            "51200\n",
            "30.706103515625\n",
            "51200\n",
            "30.4196826171875\n",
            "51200\n",
            "30.24394775390625\n",
            "51200\n",
            "30.11994873046875\n",
            "51200\n",
            "30.1342431640625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_pred = eval(tensor_eng, tensor_hin, encoder, decoder, num_of_enc_layers, num_of_dec_layers, \"GRU\")"
      ],
      "metadata": {
        "id": "9kejVozOEl_o"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor(trained_pred)\n",
        "temp = temp.view(23, 51200)\n",
        "pred_up = temp.T.to(device_name)"
      ],
      "metadata": {
        "id": "LyHQWp5kI_gP"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateAccuracy(y_pred, y_true):\n",
        "  correct = torch.eq(y_pred, y_true)\n",
        "\n",
        "  # calculate accuracy\n",
        "  accuracy = torch.mean(correct.float())\n",
        "\n",
        "  print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "id": "4kA10NUNLaqR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculateAccuracy(pred_up, tensor_hin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF2NuCcNDKZc",
        "outputId": "6f74eb3b-ba57-4050-f80c-0e3a70faaace"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.16736668348312378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/FDL_A3/hin/hin_test.csv', names=['eng','hin'])\n",
        "eng_words = df_test['eng']\n",
        "maxlen = len(max(df['eng'], key=len))\n",
        "index_eng_words = []\n",
        "for eng_word in eng_words:\n",
        "  index_eng_word = [eng_to_int[i] for i in eng_word]\n",
        "  l = len(index_eng_word)\n",
        "  index_eng_word.extend([0]*(maxlen-l+2))\n",
        "  index_eng_words.append(index_eng_word)\n",
        "\n",
        "tensor_eng_test = torch.tensor(index_eng_words).to(device_name)\n",
        "tensor_hin_test = torch.tensor(index_hin_words).to(device_name)"
      ],
      "metadata": {
        "id": "O4N6_to6CIrp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_value = eval(tensor_eng_test, tensor_hin_test, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "rBsT_3WzDSg-",
        "outputId": "77a1f39a-8e11-4577-9464-6f94980454cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b82a46ffc905>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_eng_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_hin_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: eval() missing 5 required positional arguments: 'encoder', 'decoder', 'num_of_enc_layers', 'num_of_dec_layers', and 'cell_type'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experimental Area**"
      ],
      "metadata": {
        "id": "6h-qHdB__elc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = len(max(df['eng'], key=len))"
      ],
      "metadata": {
        "id": "YnM5xI7J_uUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tensor_eng)"
      ],
      "metadata": {
        "id": "ic1s-nqVAHFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df['eng']:\n",
        "  if(len(i) > 24):\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "f8o8cuGzAInq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2,3,4]\n",
        "a.append(0*4)\n",
        "a"
      ],
      "metadata": {
        "id": "6OpbtU_mARaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.random()"
      ],
      "metadata": {
        "id": "5ZO63eD6IhUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in zip(tensor_eng, tensor_hin):\n",
        "  print(x,y)"
      ],
      "metadata": {
        "id": "SUdsTZzTs3P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X4wZuIxvvGHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "7c639dc9-aaf1-458d-9cd8-bb39012c6ebd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([26, 66])\n",
            "torch.Size([23])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9eb4e86b350c>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (26) to match target batch_size (23)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SK14JJd60Ofz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}